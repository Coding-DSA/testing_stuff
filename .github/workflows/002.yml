on:
  push:
  workflow_dispatch:

jobs:
  run-script:
    runs-on: ubuntu-latest
    environment: dev
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Verify Files After Checkout
        run: ls -R  # Debugging step to verify file existence

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests azure-identity azure-mgmt-purview azure-mgmt-resource azure-purview-catalog

      - name: Create Sample CSV File (For Testing, If Missing)
        run: |
          if [ ! -f "PythonFolder/azure_cosmos_db_onboarding.csv" ]; then
            mkdir -p PythonFolder
            echo "id,DatasourceName,DatabaseName,Kind,Endpoint" > PythonFolder/azure_cosmos_db_onboarding.csv
            echo "1,TestSource,testdb,AzureCosmosDB,https://example.com" >> PythonFolder/azure_cosmos_db_onboarding.csv
          fi

      - name: Read Parameter File and Onboard New Data Sources
        id: read_csv_python
        run: |
          python - <<EOF
          import csv, os, json

          file_path = "PythonFolder/azure_cosmos_db_onboarding.csv"
          if not os.path.exists(file_path):
              print(f"Error: CSV file not found at {file_path}")
              exit(1)

          with open(file_path, "r") as file:
              reader = csv.DictReader(file)
              data_rows = list(reader)

          if not data_rows:
              print("Error: CSV file is empty")
              exit(1)

          # Simulating filtering of new data sources
          filtered_data = [row for row in data_rows if row["DatabaseName"] not in ["ExistingDB1", "ExistingDB2"]]

          with open("filtered_data.json", "w") as f:
              json.dump(filtered_data, f, indent=4)

          print(f"Filtered Data Saved: {len(filtered_data)} entries")
          EOF

      - name: Verify JSON Output
        run: |
          if [ ! -s "filtered_data.json" ]; then
            echo "Error: JSON output file is empty!"
            exit 1
          fi
          cat filtered_data.json  # Print contents for debugging

      - name: Upload Filtered Data as Artifact
        uses: actions/upload-artifact@v4
        with:
          name: filtered-data
          path: filtered_data.json

  processed-data:
    needs: run-script
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download Filtered Data Artifact
        uses: actions/download-artifact@v4
        with:
          name: filtered-data

      - name: Verify Downloaded JSON
        run: |
          if [ ! -s "filtered_data.json" ]; then
            echo "Error: JSON file is empty or missing!"
            exit 1
          fi
          cat filtered_data.json  # Debugging

      - name: Process Filtered Data
        run: |
          python - <<EOF
          import json

          try:
              with open("filtered_data.json", "r") as f:
                  filtered_data = json.load(f)
          except Exception as e:
              print(f"JSON decoding error: {e}")
              exit(1)

          if not filtered_data:
              print("No new data sources found.")
              exit(0)

          for item in filtered_data:
              print("Deploying data source:")
              for key, value in item.items():
                  print(f"- {key}: {value}")
          EOF
